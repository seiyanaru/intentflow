### 研究進捗ログ（251213–260113）

このREADMEは、`TCFormer_Hybrid(+TTT)` 系の **性能崩壊（特にHGD）** と **被験者ごとの不安定性（BCIC 2a: S1劣化、S2/S5改善）** を解決するために行った検証を、再現可能な形で整理するためのメモです。

---

### 1. 背景・課題（なにが起きているか）

- **課題A: HGDでの catastrophic degradation（過適応）**
  - Hybrid/TTT 系のテスト時適応が、特定条件で **精度を大幅に悪化**させる。
  - 既に良い被験者の精度を保ったまま、低性能被験者だけを改善する「安全なTTA」が必要。

- **課題B: BCIC 2a で動的ゲーティング時に被験者差が極端**
  - **S2/S5が+10%程度改善**する一方で、**S1が大幅に劣化**するケースが観測される。
  - 「いつ/どのサンプルで/どれくらい更新した結果、予測がどう変わったか」を試行単位で可視化し、原因を言語化したい。

---

### 2. これまでの主要な仮説

- **仮説1（過適応）**: テスト時にTTTの更新が走りすぎる、または不確実（高エントロピー）サンプルで更新してしまい、表現が崩れて精度が落ちる。
- **仮説2（ゲーティングの副作用）**: 動的ゲーティング（entropy→α / lr_scale）が被験者によって「更新比率」「更新強度」「flip（正誤反転）」の分布を変え、S1だけ悪い方向のflipが増える。
- **仮説3（順序依存）**: drift gate を入れる場合、試行順序（`shuffle=False`）が前提であり、順序が崩れると判定が破綻する。

---

### 3. 実装した対策（Safe TTA: E2/E3の設計方針）

Safe TTAは「重い/危険な更新（TTTLinearの重み更新）」を止め、**LayerNormのaffine（γ/β）のみ**を慎重に更新する方針です。

- **E2: safe_ln**
  - **TTTLinearの重み更新を完全に無効化**
  - 更新対象は **`torch.nn.LayerNorm` の affine（γ/β）だけ**
  - **高信頼サンプルのみ更新**（`tau_conf` でフィルタ）
  - Lossは以下の合成：
    - **Consistency loss**（weak/strong augmentation間の整合性）
    - **Anchor regularization**（初期LNパラメータへのL2拘束）

- **E3: safe_ln_drift**
  - E2 + **Drift gate**
  - 直前試行との特徴変化（cosine drift）が大きいときのみ更新（`tau_drift`）
  - 目的：不要な常時更新を防ぎ「状態が変わったときだけ」適応させる。

---

### 4. 2-pass dynamic gating（BCIC 2a向け）の狙い

「不確実性（entropy）が高いときだけ2回目（適応付き）推論を行う」ことで、更新回数と副作用を抑える。

- **Pass1**: 推論のみ（TTT OFF / no-grad）で `entropy_before` を測る
- **Pass2**: `entropy_before > threshold` のときだけ、適応（TTTまたは安全更新）を許可して推論

この2-passの詳細ログを取り、**S1が落ちる理由を flip / update / delta で特定**する。

---

### 5. コードの変更点（どこを触ったか）

以下は「Safe TTA（LN-only）」「2-passデバッグ」「ドリフト計算」までを支える主要変更点です。

- **`intentflow/offline/models/tcformer_ttt/ttt_layer.py`**
  - `safe_tta_disable_ttt` を `TTTConfig` に追加
  - `TTTBase.forward()` で、`safe_tta_disable_ttt=True` のとき **TTT更新をバイパス**
  - `TTTLinear` にデバッグ用の `last_grad_norm_per_sample` / `last_clip_hit_per_sample` を保持

- **`intentflow/offline/models/tcformer/classification_module.py`**
  - `on_test_start()` で **全パラメータfreeze → LayerNormのみ学習可能**に切替
  - LN初期値 `_ln_phi0` を保存し **anchor正則化**に使用
  - `_tta_update(x)` を実装（consistency + anchor、grad clip対応、evalのまま勾配ON）
  - `test_step()` で **Pass1/Pass2の予測・確率・entropy・flip** を収集
  - `on_test_epoch_end()` で **flip解析 / update_ratio / drift統計** をJSONに保存

- **`intentflow/offline/models/tcformer_ttt/tcformer_hybrid.py`**
  - Pass1の `logits/probs/preds/entropy` を debug buffer として保存
  - `get_debug_batch()` で取り出せるようにし、2-pass解析に利用

- **`intentflow/offline/train_pipeline.py`**
  - `tta_mode` 有効時に `Trainer(inference_mode=False)` とし、テスト時更新を許可

---

### 6. 実験の再現（実行スクリプト/出力）

#### 6.1 BCIC 2a（2-pass）を全被験者で回す

- 実行スクリプト：`intentflow/offline/run_bcic2a_2pass_all.sh`
  - `run_bcic2a_2pass.py` を呼び、結果ディレクトリを作成
  - その後 `visualize_2pass.py` で図を生成

実行例（GPU0、閾値0.85）：

```bash
cd intentflow/offline
./run_bcic2a_2pass_all.sh 0 0.85
```

出力（例）：

- `intentflow/offline/results/bcic2a_2pass/<timestamp>/`
  - `debug_s{subject}_TCFormer_Hybrid.json`（被験者ごとの集計）
  - `twopass_s{subject}_TCFormer_Hybrid.json`（試行ごとの詳細）
  - `history_s{subject}_TCFormer_Hybrid.json`（学習ログ/推論ログ）
  - `figures/`（可視化）

#### 6.2 可視化（2-passデバッグの図）

スクリプト：`intentflow/offline/visualize_2pass.py`

生成したい図（現状の設計）：

- **Entropy分布（before/after、正誤色分け）**
- **delta分布（delta_KL / delta_logits、グループ別）**
  - correct→correct / correct→wrong / wrong→correct / wrong→wrong
- **Confusion matrix差分**
- **alpha vs entropy散布図、update on/off、lr_scale**

---

### 7. デバッグで残したいログ項目（2-pass動的ゲーティング）

試行ごとに最低限ほしい値（設計上の要求）：

- `y_before`, `p_before`, `pred_before`, `entropy_before`, `pmax_before`
- `alpha`, `lr_scale`, `update_on_off`
- `grad_norm`, `clip_hit`, `delta_param_norm`
- `y_after`, `p_after`, `pred_after`, `entropy_after`, `pmax_after`
- `delta_logits`, `delta_KL`

目的：**S1だけ「updateの当たり方」または「deltaが大きすぎる/方向が悪い」**などの差を、統計と図で特定する。

---

### 8. 既知の落とし穴と修正（Must Fix含む）

- **落とし穴: E2/E3でTTTが無効化されない**
  - YAMLに `safe_tta_disable_ttt: false` が常在すると、`kwargs` の「存在判定」で false が優先され、`tta_mode` からの自動推論が効かない。
  - 対策：`safe_tta_disable_ttt: null` にするか、コード側を「None判定」に変更。

- **公平性: E0 vs E1がtrain差になり得る**
  - forward分岐が学習中にも影響するため、実験設計によっては「テスト時のみの差」にならない。
  - 目的が「test-only差分」なら、同一checkpointでtest条件だけ切り替える必要がある。

- **安定性: `_tta_update` で `train()` にしない**
  - dropout等が有効化されるとTTAが不安定になりやすい。
  - evalのまま `torch.enable_grad(True)` でLNのみ更新する。

- **数値安定性: KLで `p_w.log()` の前に clamp**
  - `p_w.clamp(min=1e-12).log()` のようにしてlog(0)を回避。

---

### 9. 現状の未解決点（次にやること）

- **HGDの崩壊が「どの条件で」「どのサンプルで」起きるか**を、同様の粒度（trial単位ログ）で再現し、E2/E3での抑制効果を確認する。
- **BCIC 2a: S1劣化の原因特定**
  - flip解析（to_wrongが多いか、特定クラスが崩れるか）
  - update_ratio / alpha / lr_scale / delta_KL の分布差
  - confusion差分で「どの誤りが増えたか」

---

### 10. 実行環境メモ（2026-01時点）

- `transformers` が未インストールだと `ttt_layer.py` の import で落ちる。
  - 現環境では `pip3 install transformers --user` を実施して解消したが、`packaging` の依存警告が出る場合がある（必要なら `pip3 install -U packaging --user` を検討）。

